{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 4: Evaluation and Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Cross Validation\n",
    "\n",
    "We're going to do some evaluations on the language prediction algorithms we build last week.\n",
    "\n",
    "## Setting Up Swadesh NB and SVM Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import swadesh\n",
    "import numpy as np\n",
    "\n",
    "en = swadesh.words('en')\n",
    "de = swadesh.words('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup the data \n",
    "import string\n",
    "def vecRepr(word):\n",
    "    return [word.count(l) for l in string.ascii_lowercase]\n",
    "\n",
    "Xwords_all = np.array([w.lower() for w in en] + [w.lower() for w in de])\n",
    "Ywords_all = np.array([0 for _ in en] + [1 for _ in de])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from Lab 3 Q4\n",
    "# an nb classifier class based on last weeks example\n",
    "# it's good to know how to build classes in python, but is not required for the assignments or exam!\n",
    "from sklearn import base\n",
    "class nbLanguagePredictor(base.BaseEstimator):\n",
    "    def __init__(self):\n",
    "        # set internal variables to dummy values\n",
    "        self.langLetters = None\n",
    "        self.numLangLetters = None\n",
    "        \n",
    "    def fit(self, langwords, langlabels):\n",
    "        # fit model using supplied word lists and language labels\n",
    "        lang0words = [w for w,lang in zip(langwords, langlabels) if lang==0]\n",
    "        lang1words = [w for w,lang in zip(langwords, langlabels) if lang==1]\n",
    "        self.langLetters = tuple(''.join(words).lower() for words in (lang0words, lang1words))\n",
    "        self.numLangLetters = tuple(map(len, self.langLetters))\n",
    "        \n",
    "    def calculate_probability(self, word, language):\n",
    "        # calculate probability word is from first language \n",
    "        # (note: the `language` parameter should be 0 or 1)\n",
    "        return 0.5 * np.prod([self.langLetters[language].count(letter)/self.numLangLetters[language] \n",
    "                              for letter in word])\n",
    "\n",
    "    def naive_bayes(self, word):\n",
    "        first_prob = self.calculate_probability(word, 0)\n",
    "        second_prob = self.calculate_probability(word, 1)\n",
    "        if first_prob > second_prob:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    def predict(self, words):\n",
    "        if not self.langLetters:\n",
    "            raise ValueError(\"Model not trained!\")\n",
    "        return np.array([self.naive_bayes(word) for word in words])\n",
    "    \n",
    "    def score(self, words, langs):\n",
    "        return sum(self.predict(words)==langs)/len(langs)\n",
    "\n",
    "nb_alldata = nbLanguagePredictor()\n",
    "nb_alldata.fit(Xwords_all,Ywords_all)\n",
    "nb_alldata.predict(['gewürztraminer','discombublate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from lab 3 Q5\n",
    "from sklearn import svm\n",
    "\n",
    "svc_all = svm.SVC()\n",
    "svc_all.fit(list(map(vecRepr,Xwords_all)), Ywords_all)\n",
    "svc_all.predict([vecRepr(\"gewürztraminer\"), vecRepr(\"discombublate\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Test and Training Sets\n",
    "\n",
    "Selecting test and training sets is not always as simple as it may seem. You can do a simple random sample, but it's often better to make a *stratified sample* where the proportions of each class are the same in the test and training data. Scikit-learn has a handy function for doing that.\n",
    "\n",
    "Here's an example using the iris data set you saw last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : (150, 4) (150,)\n",
      "train: (90, 4) (90,)\n",
      "test : (60, 4) (60,)\n"
     ]
    }
   ],
   "source": [
    "# `sklearn` has a handy class for creating training and test subsets of your data.\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# note: random_state=0 makes the random numbers the same each time we run this.\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "\n",
    "print(\"data :\", iris.data.shape, iris.target.shape)\n",
    "print(\"train:\", X_train.shape,   y_train.shape)\n",
    "print(\"test :\", X_test.shape,    y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94999999999999996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get accuracy scores for the model\n",
    "from sklearn import svm\n",
    "svm_iris = svm.SVC().fit(X_train, y_train)\n",
    "svm_iris.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision, Recall and F-measure\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg\", style=\"width: 250px; float: right\"/>\n",
    "\n",
    "Recall the confusion matrix for a binary classifier:\n",
    "\n",
    "|              | predict T | predict F |\n",
    "| --------     | --------- | --------- |\n",
    "| actual **T** |    TP     |    FN     |\n",
    "| actual **F** |    FP     |    TN     |\n",
    "\n",
    "and formulas for **precision**, **recall** and **$F_1$ measure**:\n",
    "\n",
    "> $P=\\frac{TP}{TP+FP}$ \n",
    "\n",
    "> $R=\\frac{TP}{TP+FN}$ \n",
    "\n",
    "> $F_1 = \\frac{2PR}{P+R}$\n",
    "\n",
    "(image from Wikipedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1.\n",
    "\n",
    "\n",
    "Generate training and test sets with 80%/20% split with the swadesh data and train SVM and NB classifiers on the training data.\n",
    "\n",
    "Calculate the **confusion matrix**, **precision**, **recall** and $F_1$ measure for your classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB - precision:  0.6333333333333333  recall:  0.7125 F1:  0.6705882352941177\n",
      "SV - precision:  0.6986301369863014  recall:  0.6375 F1:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "w_train, w_test, l_train, l_test = cross_validation.train_test_split(\n",
    "        Xwords_all, Ywords_all, test_size=0.4, random_state=0)\n",
    "\n",
    "nbTrained = nbLanguagePredictor()\n",
    "nbTrained.fit(w_train, l_train)\n",
    "\n",
    "svcTrained = svm.SVC()\n",
    "svcTrained.fit(list(map(vecRepr,w_train)), l_train)\n",
    "\n",
    "nbPredicts = nbTrained.predict(w_test)\n",
    "svcPredicts = svcTrained.predict(list(map(vecRepr,w_test)))\n",
    "\n",
    "nbTP = sum(1 for lp,l in zip(nbPredicts, l_test) if lp and l)\n",
    "nbFP = sum(1 for lp,l in zip(nbPredicts, l_test) if lp and not l)\n",
    "nbTN = sum(1 for lp,l in zip(nbPredicts, l_test) if not lp and not l)\n",
    "nbFN = sum(1 for lp,l in zip(nbPredicts, l_test) if not lp and l)\n",
    "\n",
    "nbPrecision = nbTP/(nbTP+nbFP)\n",
    "nbRecall    = nbTP/(nbTP+nbFN)\n",
    "nbF1        = 2*nbPrecision*nbRecall/(nbPrecision+nbRecall)\n",
    "print(\"NB - precision: \", nbPrecision, \" recall: \", nbRecall, \"F1: \", nbF1)\n",
    "\n",
    "svcTP = sum(1 for lp,l in zip(svcPredicts, l_test) if lp and l)\n",
    "svcFP = sum(1 for lp,l in zip(svcPredicts, l_test) if lp and not l)\n",
    "svcTN = sum(1 for lp,l in zip(svcPredicts, l_test) if not lp and not l)\n",
    "svcFN = sum(1 for lp,l in zip(svcPredicts, l_test) if not lp and l)\n",
    "\n",
    "svcPrecision = svcTP/(svcTP+svcFP)\n",
    "svcRecall    = svcTP/(svcTP+svcFN)\n",
    "svcF1        = 2*svcPrecision*svcRecall/(svcPrecision+svcRecall)\n",
    "print(\"SV - precision: \", svcPrecision, \" recall: \", svcRecall, \"F1: \", svcF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "Cross validation, dividing your data into $n$ subsets, training the model $n$ times with one of the subsets left out, then testing each corresponding trained model on the left out subsets.\n",
    "\n",
    "`sklearn` also has a handy helper class for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies for each fold: [ 0.96666667  1.          0.96666667  0.96666667  1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "scores = cross_validation.cross_val_score(svm_iris, iris.data, iris.target, cv=5)\n",
    "print(\"Accuracies for each fold:\",scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.\n",
    "\n",
    "Do 10-fold cross validation on the two swadesh language detection models, calculating accuracy for each fold and average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies for each svc fold: [ 0.57142857  0.64285714  0.52380952  0.54761905  0.83333333  0.85714286\n",
      "  0.85714286  0.65        0.55        0.725     ]\n",
      "Accuracies for each nb  fold: [ 0.66666667  0.61904762  0.54761905  0.61904762  0.70731707  0.68292683\n",
      "  0.46341463  0.90243902  0.82926829  0.68292683]\n",
      "Average accuracy for svc: 0.675833333333\n",
      "Average accuracy for nb : 0.672067363531\n"
     ]
    }
   ],
   "source": [
    "svcScores = cross_validation.cross_val_score(svm.SVC(), list(map(vecRepr,Xwords_all)), Ywords_all, cv=10)\n",
    "nbScores = cross_validation.cross_val_score(nbLanguagePredictor(), Xwords_all, Ywords_all, cv=10)\n",
    "print(\"Accuracies for each svc fold:\",svcScores)\n",
    "print(\"Accuracies for each nb  fold:\",nbScores)\n",
    "print(\"Average accuracy for svc:\",np.average(svcScores))\n",
    "print(\"Average accuracy for nb :\",np.average(nbScores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Indexing and More Cross Validation\n",
    "\n",
    "Unfortunately, there's no handy method for calculating precision and recall for each fold. There are, however, handy methods to set up cross-validation manually given a little extra work.\n",
    "\n",
    "With numpy arrays, you can use a list of indexes to select elements of the array. The scikit-learn `StratifiedKFold` class provides an iterator (you can use in for loops etc...) that returns lists of training and test indexes in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "train [0 1 3 4 6 7 8 9]\n",
      "test  [2 5]\n",
      "\n",
      "fold 1\n",
      "train [1 2 3 4 5 6 8 9]\n",
      "test  [0 7]\n",
      "\n",
      "fold 2\n",
      "train [0 2 3 4 5 7 8 9]\n",
      "test  [1 6]\n",
      "\n",
      "fold 3\n",
      "train [0 1 2 4 5 6 7 8]\n",
      "test  [3 9]\n",
      "\n",
      "fold 4\n",
      "train [0 1 2 3 5 6 7 9]\n",
      "test  [4 8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[10, 20], [30, 40], [15, 25], [35, 45], [11, 21], [31, 41], [12, 22], [32, 42], [13, 23], [33, 43]])\n",
    "y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "\n",
    "cv = cross_validation.StratifiedKFold(y, n_folds=5, shuffle=True, random_state=0)\n",
    "fold = 0\n",
    "for train_indexes, test_indexes in cv:\n",
    "    print(\"fold\",fold)\n",
    "    print(\"train\", train_indexes)\n",
    "    print(\"test \", test_indexes)\n",
    "    print()\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "training x: [[10 20]\n",
      " [30 40]\n",
      " [35 45]\n",
      " [11 21]\n",
      " [12 22]\n",
      " [32 42]\n",
      " [13 23]\n",
      " [33 43]]\n",
      "training y: [0 0 0 0 1 1 1 1]\n",
      "testing  x: [[15 25]\n",
      " [31 41]]\n",
      "testing  y: [0 1]\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "for train_indexes, test_indexes in cv:\n",
    "    print(\"fold\",fold)\n",
    "    X_train, X_test = X[train_indexes], X[test_indexes]\n",
    "    y_train, y_test = y[train_indexes], y[test_indexes]\n",
    "    print(\"training x:\", X_train)\n",
    "    print(\"training y:\", y_train)\n",
    "    print(\"testing  x:\", X_test)\n",
    "    print(\"testing  y:\", y_test)\n",
    "    fold += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3.\n",
    "\n",
    "The best way to calculate F-measures for cross validation is to add up the true positives etc...  for each fold, using the combined counts co calculate the F-measure.\n",
    "\n",
    "Do a 10-fold cross validation on the NB and SVM swadesh language classifiers using `StratifiedKFold`. \n",
    "\n",
    "Calculate the overall $F_1$ measure for each of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB  - precision:  0.6769911504424779  recall:  0.7391304347826086 F1:  0.7066974595842956\n",
      "SVM - precision:  0.7615894039735099  recall:  0.5555555555555556 F1:  0.6424581005586593\n"
     ]
    }
   ],
   "source": [
    "cv = cross_validation.StratifiedKFold(Ywords_all, n_folds=10, shuffle=True, random_state=0)\n",
    "fold = 0\n",
    "models = (nbLanguagePredictor(), svm.SVC())\n",
    "predictions = ([],[])\n",
    "realvals = ([],[])\n",
    "for train_indexes, test_indexes in cv:\n",
    "    for model,pred,real,name in zip(models, predictions, realvals,{\"NB \",\"SVM\"}):\n",
    "        trainWords, testWords = Xwords_all[train_indexes], Xwords_all[test_indexes]\n",
    "        if name==\"SVM\":\n",
    "            trainWords, testWords = list(map(vecRepr,trainWords)), list(map(vecRepr,testWords))\n",
    "        model.fit(trainWords, Ywords_all[train_indexes])\n",
    "        thisPred = model.predict(testWords)\n",
    "        pred.extend(thisPred)\n",
    "        real.extend(Ywords_all[test_indexes])\n",
    "    fold += 1\n",
    "TP = [sum(1 for lp,l in zip(pred, real) if lp and l) for pred,real in zip(predictions, realvals)]\n",
    "FP = [sum(1 for lp,l in zip(pred, real) if lp and not l) for pred,real in zip(predictions, realvals)]\n",
    "TN = [sum(1 for lp,l in zip(pred, real) if not lp and not l) for pred,real in zip(predictions, realvals)]\n",
    "FN = [sum(1 for lp,l in zip(pred, real) if not lp and l) for pred,real in zip(predictions, realvals)]\n",
    "\n",
    "Precision = [tp/(tp+fp) for tp,fp in zip(TP,FP)]\n",
    "Recall    = [tp/(tp+fn) for tp,fn in zip(TP,FN)]\n",
    "F1        = [2*P*R/(P+R) for P,R in zip(Precision, Recall)]\n",
    "print(\"NB  - precision: \", Precision[0], \" recall: \", Recall[0], \"F1: \", F1[0])\n",
    "print(\"SVM - precision: \", Precision[1], \" recall: \", Recall[1], \"F1: \", F1[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
